{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Convolutional Exploration\n",
    "### non-technical report\n",
    "_Gus Ostow_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal was never to change the world with my capstone, not even to put together a novel analysis or model. All I wanted was to build a rock solid set of specialized skills in computer vision. The objective of the computer vision field is to program computers to gain human-level insight from images and videos. To familiarize myself with the field, I set out to replicate and understand state of the art neural network models on the CIFAR-10 image classification benchmark. The task leaves little room for innovation; human level accuracy has already been surpassed, which is fine. The project was ideal to boost me to the forefront of research. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "Data scientists never stop whining about how the majority of their time is spent collecting data, extracting data, cleaning data, munging data, aka \"eating shit\", with only a sliver of time left for juicy modeling. Well, not in my case. I chose to work with a popular premade dataset. CIFAR-10 consists of 60,000 tiny (32 x 32) images in ten different class categories. Classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. More information on the CIFAR image datasets can be found at https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\n",
    "<img src=\"images/1.png\",width=450,height=150, align = left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks - Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal was to build a model than can classify the CIFAR-10 as well as a human. Up until a few years ago, achieving human-level accuracy on perceptual tasks was a fool's errand. For good reason. Image classification is tough. Images of cars vary in infinite ways. A car is still a car regardless of lighting, orientation, blur, or any other low-level visual feature. Most machine learning algorithms are hopeless at picking out the invariance of object categories. The conventional computer vision approach was to painstakingly hand-code rules about the pixels that might distinguish image classes. Success was limited. \n",
    "\n",
    "In 2012, everything changed with the advent of deep convolutional networks. Krizhevsky et al. rendered conventional computer vision techniques obsolete. His eponymously named AlexNet outperformed all previous best efforts on ImageNet, a popular benchmark. Deep convolutional neural networks trained on GPUs became the new computer vision paradigm.\n",
    "\n",
    "Before I get into convolutional networks, let's briefly review artificial neural networks more generally. Neural nets have been around for awhile, but have only recently gained practical value and popularity due to modern day computing power. No longer merely an intellectual exercise, neural networks are generating hype under their re-branded name, \"deep learning\". \n",
    "\n",
    "A neural network is organized into sequential layers. Each layer contains some number of units, sometimes called \"neurons\". Input data is fed into the first layer. Activation then spreads forward through the units in each layer until the output layer. The final activity of the output layer is a prediction based on the initial input data. Activation depends on the weights of the connections between units. \n",
    "\n",
    "Let's say you want to predict if an image contains a cat or a dog. You could build a neural network that has the same number of units in its first layer as pixels in the images. That way you can input an image to the network by feeding its pixel values as numbers into each unit. The last layer would only need two units, one for cat and one for dog. If the cat unit activates more for a picture, then the network predicts cat. \n",
    "\n",
    "The model's prediction depends on the connection weights between units. A model needs the perfect set of connection weights to accurately distinguish cats and dogs. How does the model get these weights? It learns. That is the magic of neural networks. You can train a neural network on many pictures of cats and dogs with the correct labels. The network changes its connection weights until it correctly makes predictions that match the labels. After training the model will be able to make predictions on picture it had never seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [keras]",
   "language": "python",
   "name": "Python [keras]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
