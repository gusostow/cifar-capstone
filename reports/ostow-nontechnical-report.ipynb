{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Convolutional Exploration\n",
    "### non-technical report\n",
    "_Gus Ostow_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal was never to change the world with my capstone, not even to put together a novel analysis or model. All I wanted was to build a rock solid set of specialized skills in computer vision. The objective of the computer vision field is to program computers to gain human-level insight from images and videos. To familiarize myself with the field, I set out to replicate and understand state of the art neural network models on the CIFAR-10 image classification benchmark. The task leaves little room for innovation; human level accuracy has already been surpassed, which is fine. The project was ideal to boost me to the forefront of research. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "Data scientists never stop whining about how the majority of their time is spent collecting data, extracting data, cleaning data, munging data, aka \"eating shit\", with only a sliver of time left for juicy modeling. Well, not in my case. I chose to work with a popular premade dataset. CIFAR-10 consists of 60,000 tiny (32 x 32) images in ten different class categories. Classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. More information on the CIFAR image datasets can be found at https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\n",
    "<img src=\"images/1.png\",width=450,height=150, align = left>\n",
    "\n",
    "My goal was to build a model than can classify the CIFAR-10 as well as a human. Up until a few years ago, achieving human-level accuracy on perceptual tasks was a fool's errand. For good reason. Image classification is tough. Images of cars vary in infinite ways. A car is still a car regardless of lighting, orientation, blur, or any other low-level visual feature. Most machine learning algorithms are hopeless at picking out the invariance of object categories. The conventional computer vision approach was to painstakingly hand-code rules about the pixels that might distinguish image classes. Success was limited. \n",
    "\n",
    "In 2012, everything changed with the advent of deep convolutional networks. Krizhevsky et al. rendered conventional computer vision techniques obsolete. His eponymously named AlexNet outperformed all previous best efforts on ImageNet, a popular benchmark. Deep convolutional neural networks trained on GPUs became the new computer vision paradigm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks - Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I get into convolutional networks, let's briefly review artificial neural networks more generally. Neural nets have been around for awhile, but have only recently gained practical value and popularity due to modern day computing power. No longer merely an intellectual exercise, neural networks are generating hype under their re-branded name, \"deep learning\". \n",
    "\n",
    "A neural network is organized into sequential layers. Each layer contains some number of units, sometimes called \"neurons\". Input data is fed into the first layer. Activation then spreads forward through the units in each layer until the output layer. The final activity of the output layer is a prediction based on the initial input data. Activation depends on the weights of the connections between units. \n",
    "\n",
    "Below is an image of a basic feed-forward neural network: \n",
    "\n",
    "<p><img src=\"images/3.jpeg\",width=450,height=150, align = left></p>\n",
    "\n",
    "\n",
    "\n",
    "Let's say you want to predict if an image contains a cat or a dog. You could build a neural network that has the same number of units in its first layer as pixels in the images. That way you can input an image to the network by feeding its pixel values as numbers into each unit. The last layer would only need two units, one for cat and one for dog. If the cat unit activates more for a picture, then the network predicts cat. \n",
    "\n",
    "The model's prediction depends on the connection weights between units. A model needs the perfect set of connection weights to accurately distinguish cats and dogs. How does the model get these weights? It learns. That is the magic of neural networks. You can train a neural network on many pictures of cats and dogs with the correct labels. The network changes its connection weights until it correctly makes predictions that match the labels. After training the model will be able to make predictions on pictures it had never seen before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Image classification is so difficult that despite all their power, standard neural networks can barely score greater than 50% on the CIFAR-10 benchmark. Convolutional neural networks are specialized to do better on visual tasks by exploiting the spacial quality of images. \n",
    "\n",
    "A CNN transforms images by passing them through a series of convolutional layers. Each layer compares its input to a set of learned filters. Filters are small visual squares, usually 3x3 pixels, that are connection weights learned via a training set. After comparison with the filters, the convolutional layers produces an output volume. Interpret a slice of the output volume as the aspects of the input image that match its parent filter. For example, a filter might only like vertical edges so it would would produce feature map of an image that only visualizes its vertical edges. \n",
    "\n",
    "Hierarchically organized convolutional layers apply transformations to images complex enough to pick out invariant features relevant to the classification task. Early layers learn filters sensitive to basic visual features, like edges. Later layers use the resultant feature maps of the filters, to search for more complex invariant features, like a dogs face or the wheels of a car. \n",
    "\n",
    "Below is an image of a convolutional neural network: \n",
    "\n",
    "<img src=\"images/5.png\",width=880,height=240, align = left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Convolutional neural networks have proven themselves as the state of the art for image tasks. I didn't need to think hard about what tool would be best for classifying the CIFAR-10 dataset. Despite preordained success, I did not start with CNNs. Much of the knowledge base I needed still relied on universal principles of neural networks. Starting simple was the smart thing to do. I chose this project to learn about neural nets, not to break world records.\n",
    "\n",
    "Fully connected feed-forward networks have limited potential for image classification tasks. I would graduate to CNNs once I exhausted that potential. \n",
    "\n",
    "I used Keras to build my models. [Keras](https://keras.io/) is a neural network package that runs on top of a numerical computation backend (either TensorFlow or Theano). TensorFlow's automatic differentation and tensor operations makes neural networks easy, with Keras on top of TensorFlow it's downright accessible. A simple network only takes a few lines, not many more than fitting a model in Sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed forward (FFN)\n",
    "\n",
    "Even though it is trivial to build a model end-to-end in Keras, an effective model still takes thought. Even simple feed forward networks involve scores of choices. A quick list: network topology, optimizer, learning rate and other optimizer parameters, activation function, regularization, weight initialization, and more.\n",
    "\n",
    "I will briefly give an overview of two of the many essential design decisions that go into a FFN.\n",
    "\n",
    "**Topology - **\n",
    "How many layers deep is the network? How many unit wide are the layers? Topology dictates the network's representational complexity.\n",
    "\n",
    "**Optimizer - **\n",
    "The optimizer updates the model parameters, or weights, based on minimizing the loss function. The loss function measures the model's performance with respect to its weights. It is zero for a perfect model. The central question of the optimizer: how can I change the model weights to minimize loss? Optimizers answer that question by using the gradient, which can be interpreted as the direction of steepest ascent on the loss function. Update the parameters in the direction of steepest descent and your are one step toward minimizing the loss function and training your model. \n",
    "Stochastic gradient decent is the most generic optimizer, others are AdaGrad, RmsProp, and Adam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Moving on to CNNs\n",
    "\n",
    "My time had come to understand and replicate the best efforts at image classification. Several well-known networks standout as valuable learning opportunities to replicate.\n",
    "\n",
    "**VGG - ** \n",
    "Showed that increasing depth with convolutional layers with small filter sizes improves performance.\n",
    "\n",
    "**Strided convolutions - **\n",
    "Questions the architectural assumption that dedicated pooling layers are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "My intention was not to classify images with world-accuracy. It was to learn how to classify images with world-class accuracy, which is a subtle and important distinction. My final project was about the journey, not the destination. I learned a lot about the gritty details of training neural networks, the sort of knowledge only available from hands-on tinkering. A more ambitious, \"destination oriented\", project never would have left me time to learn what I did.  \n",
    "\n",
    "I achieved state of the art accuracy on CIFAR-10 [need to fill in the details once I have more results]. \n",
    "\n",
    "Now that I am armed with a solid understanding of convolutional networks in theory and practice, I'm ready to go out and do some damage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "He, K., Zhang, X., Ren, S., & Sun, J. (2015). Deep residual learning for image recognition. arXiv preprint arXiv:1512.03385.\n",
    "\n",
    "Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167.\n",
    "\n",
    "Kingma, D., & Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.\n",
    "\n",
    "Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.\n",
    "\n",
    "Springenberg, J. T., Dosovitskiy, A., Brox, T., & Riedmiller, M. (2014). Striving for simplicity: The all convolutional net. arXiv preprint arXiv:1412.6806."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [keras]",
   "language": "python",
   "name": "Python [keras]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
